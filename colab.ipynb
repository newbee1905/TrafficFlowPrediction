{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newbee1905/TrafficFlowPrediction/blob/dev%2Fnewbee1905/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!if [ -d \"TrafficFlowPrediction\" ]; then rm -rf TrafficFlowPrediction; fi\n",
        "!git config --global user.name \"newbee1905\"\n",
        "!git clone https://github.com/newbee1905/TrafficFlowPrediction -b dev/newbee1905"
      ],
      "metadata": {
        "id": "cZTZZbsi4gOz",
        "outputId": "1bc43f00-9dac-4fcb-b8eb-02d9498970d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TrafficFlowPrediction'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/115)\u001b[K\rremote: Counting objects:   1% (2/115)\u001b[K\rremote: Counting objects:   2% (3/115)\u001b[K\rremote: Counting objects:   3% (4/115)\u001b[K\rremote: Counting objects:   4% (5/115)\u001b[K\rremote: Counting objects:   5% (6/115)\u001b[K\rremote: Counting objects:   6% (7/115)\u001b[K\rremote: Counting objects:   7% (9/115)\u001b[K\rremote: Counting objects:   8% (10/115)\u001b[K\rremote: Counting objects:   9% (11/115)\u001b[K\rremote: Counting objects:  10% (12/115)\u001b[K\rremote: Counting objects:  11% (13/115)\u001b[K\rremote: Counting objects:  12% (14/115)\u001b[K\rremote: Counting objects:  13% (15/115)\u001b[K\rremote: Counting objects:  14% (17/115)\u001b[K\rremote: Counting objects:  15% (18/115)\u001b[K\rremote: Counting objects:  16% (19/115)\u001b[K\rremote: Counting objects:  17% (20/115)\u001b[K\rremote: Counting objects:  18% (21/115)\u001b[K\rremote: Counting objects:  19% (22/115)\u001b[K\rremote: Counting objects:  20% (23/115)\u001b[K\rremote: Counting objects:  21% (25/115)\u001b[K\rremote: Counting objects:  22% (26/115)\u001b[K\rremote: Counting objects:  23% (27/115)\u001b[K\rremote: Counting objects:  24% (28/115)\u001b[K\rremote: Counting objects:  25% (29/115)\u001b[K\rremote: Counting objects:  26% (30/115)\u001b[K\rremote: Counting objects:  27% (32/115)\u001b[K\rremote: Counting objects:  28% (33/115)\u001b[K\rremote: Counting objects:  29% (34/115)\u001b[K\rremote: Counting objects:  30% (35/115)\u001b[K\rremote: Counting objects:  31% (36/115)\u001b[K\rremote: Counting objects:  32% (37/115)\u001b[K\rremote: Counting objects:  33% (38/115)\u001b[K\rremote: Counting objects:  34% (40/115)\u001b[K\rremote: Counting objects:  35% (41/115)\u001b[K\rremote: Counting objects:  36% (42/115)\u001b[K\rremote: Counting objects:  37% (43/115)\u001b[K\rremote: Counting objects:  38% (44/115)\u001b[K\rremote: Counting objects:  39% (45/115)\u001b[K\rremote: Counting objects:  40% (46/115)\u001b[K\rremote: Counting objects:  41% (48/115)\u001b[K\rremote: Counting objects:  42% (49/115)\u001b[K\rremote: Counting objects:  43% (50/115)\u001b[K\rremote: Counting objects:  44% (51/115)\u001b[K\rremote: Counting objects:  45% (52/115)\u001b[K\rremote: Counting objects:  46% (53/115)\u001b[K\rremote: Counting objects:  47% (55/115)\u001b[K\rremote: Counting objects:  48% (56/115)\u001b[K\rremote: Counting objects:  49% (57/115)\u001b[K\rremote: Counting objects:  50% (58/115)\u001b[K\rremote: Counting objects:  51% (59/115)\u001b[K\rremote: Counting objects:  52% (60/115)\u001b[K\rremote: Counting objects:  53% (61/115)\u001b[K\rremote: Counting objects:  54% (63/115)\u001b[K\rremote: Counting objects:  55% (64/115)\u001b[K\rremote: Counting objects:  56% (65/115)\u001b[K\rremote: Counting objects:  57% (66/115)\u001b[K\rremote: Counting objects:  58% (67/115)\u001b[K\rremote: Counting objects:  59% (68/115)\u001b[K\rremote: Counting objects:  60% (69/115)\u001b[K\rremote: Counting objects:  61% (71/115)\u001b[K\rremote: Counting objects:  62% (72/115)\u001b[K\rremote: Counting objects:  63% (73/115)\u001b[K\rremote: Counting objects:  64% (74/115)\u001b[K\rremote: Counting objects:  65% (75/115)\u001b[K\rremote: Counting objects:  66% (76/115)\u001b[K\rremote: Counting objects:  67% (78/115)\u001b[K\rremote: Counting objects:  68% (79/115)\u001b[K\rremote: Counting objects:  69% (80/115)\u001b[K\rremote: Counting objects:  70% (81/115)\u001b[K\rremote: Counting objects:  71% (82/115)\u001b[K\rremote: Counting objects:  72% (83/115)\u001b[K\rremote: Counting objects:  73% (84/115)\u001b[K\rremote: Counting objects:  74% (86/115)\u001b[K\rremote: Counting objects:  75% (87/115)\u001b[K\rremote: Counting objects:  76% (88/115)\u001b[K\rremote: Counting objects:  77% (89/115)\u001b[K\rremote: Counting objects:  78% (90/115)\u001b[K\rremote: Counting objects:  79% (91/115)\u001b[K\rremote: Counting objects:  80% (92/115)\u001b[K\rremote: Counting objects:  81% (94/115)\u001b[K\rremote: Counting objects:  82% (95/115)\u001b[K\rremote: Counting objects:  83% (96/115)\u001b[K\rremote: Counting objects:  84% (97/115)\u001b[K\rremote: Counting objects:  85% (98/115)\u001b[K\rremote: Counting objects:  86% (99/115)\u001b[K\rremote: Counting objects:  87% (101/115)\u001b[K\rremote: Counting objects:  88% (102/115)\u001b[K\rremote: Counting objects:  89% (103/115)\u001b[K\rremote: Counting objects:  90% (104/115)\u001b[K\rremote: Counting objects:  91% (105/115)\u001b[K\rremote: Counting objects:  92% (106/115)\u001b[K\rremote: Counting objects:  93% (107/115)\u001b[K\rremote: Counting objects:  94% (109/115)\u001b[K\rremote: Counting objects:  95% (110/115)\u001b[K\rremote: Counting objects:  96% (111/115)\u001b[K\rremote: Counting objects:  97% (112/115)\u001b[K\rremote: Counting objects:  98% (113/115)\u001b[K\rremote: Counting objects:  99% (114/115)\u001b[K\rremote: Counting objects: 100% (115/115)\u001b[K\rremote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 147 (delta 54), reused 80 (delta 28), pack-reused 32\u001b[K\n",
            "Receiving objects: 100% (147/147), 14.20 MiB | 25.97 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "dqSQc4IU8ztH",
        "outputId": "290a5559-4381-480c-a794-b9f44d2d9f24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TrafficFlowPrediction\n",
            "Requirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
            "Collecting asttokens==2.2.1 (from -r requirements.txt (line 2))\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.6.3)\n",
            "Requirement already satisfied: attrs==23.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
            "Collecting beautifulsoup4==4.12.2 (from -r requirements.txt (line 6))\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bleach==6.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (6.0.0)\n",
            "Requirement already satisfied: cachetools==5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (5.3.1)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer==3.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.2.0)\n",
            "Collecting comm==0.1.4 (from -r requirements.txt (line 11))\n",
            "  Downloading comm-0.1.4-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: contourpy==1.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.11.0)\n",
            "Collecting debugpy==1.6.7.post1 (from -r requirements.txt (line 14))\n",
            "  Downloading debugpy-1.6.7.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator==5.1.1 (from -r requirements.txt (line 15))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.7.1)\n",
            "Collecting executing==1.2.0 (from -r requirements.txt (line 17))\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: fastjsonschema==2.18.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.18.0)\n",
            "Requirement already satisfied: flatbuffers==23.5.26 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (23.5.26)\n",
            "Collecting fonttools==4.42.1 (from -r requirements.txt (line 20))\n",
            "  Downloading fonttools-4.42.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (0.4.0)\n",
            "Collecting google-auth==2.22.0 (from -r requirements.txt (line 22))\n",
            "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib==1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (1.0.0)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (0.2.0)\n",
            "Requirement already satisfied: graphviz==0.20.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (0.20.1)\n",
            "Requirement already satisfied: grpcio==1.57.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (1.57.0)\n",
            "Requirement already satisfied: h5py==3.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (3.9.0)\n",
            "Requirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (3.4)\n",
            "Collecting import-ipynb==0.1.4 (from -r requirements.txt (line 29))\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Collecting ipykernel==6.25.1 (from -r requirements.txt (line 30))\n",
            "  Downloading ipykernel-6.25.1-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==8.14.0 (from -r requirements.txt (line 31))\n",
            "  Downloading ipython-8.14.0-py3-none-any.whl (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.7/798.7 kB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi==0.19.0 (from -r requirements.txt (line 32))\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (3.1.2)\n",
            "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (1.3.2)\n",
            "Requirement already satisfied: jsonschema==4.19.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (4.19.0)\n",
            "Requirement already satisfied: jsonschema-specifications==2023.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (2023.7.1)\n",
            "Collecting jupyter_client==8.3.0 (from -r requirements.txt (line 37))\n",
            "  Downloading jupyter_client-8.3.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter_core==5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (5.3.1)\n",
            "Requirement already satisfied: jupyterlab-pygments==0.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (0.2.2)\n",
            "Collecting keras==2.13.1 (from -r requirements.txt (line 40))\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver==1.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (1.4.4)\n",
            "Requirement already satisfied: libclang==16.0.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (16.0.6)\n",
            "Requirement already satisfied: Markdown==3.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 43)) (3.4.4)\n",
            "Requirement already satisfied: MarkupSafe==2.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 44)) (2.1.3)\n",
            "Collecting matplotlib==3.7.2 (from -r requirements.txt (line 45))\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (0.1.6)\n",
            "Collecting mistune==3.0.1 (from -r requirements.txt (line 47))\n",
            "  Downloading mistune-3.0.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nbclient==0.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 48)) (0.8.0)\n",
            "Collecting nbconvert==7.7.4 (from -r requirements.txt (line 49))\n",
            "  Downloading nbconvert-7.7.4-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.6/254.6 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nbformat==5.9.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (5.9.2)\n",
            "Requirement already satisfied: nest-asyncio==1.5.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 51)) (1.5.7)\n",
            "Collecting numpy==1.24.3 (from -r requirements.txt (line 52))\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.2.4.5 (from -r requirements.txt (line 53))\n",
            "  Downloading nvidia_cublas_cu12-12.2.4.5-py3-none-manylinux1_x86_64.whl (412.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.5/412.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.2.128 (from -r requirements.txt (line 54))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.2.128-py3-none-manylinux1_x86_64.whl (845 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.8/845.8 kB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from -r requirements.txt (line 55))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m811.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 56)) (3.2.2)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 57)) (3.3.0)\n",
            "Requirement already satisfied: packaging==23.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 58)) (23.1)\n",
            "Collecting pandas==2.0.3 (from -r requirements.txt (line 59))\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m130.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandocfilters==1.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 60)) (1.5.0)\n",
            "Requirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 61)) (0.8.3)\n",
            "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 62)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 63)) (0.7.5)\n",
            "Collecting Pillow==10.0.0 (from -r requirements.txt (line 64))\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs==3.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 65)) (3.10.0)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.39 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 66)) (3.0.39)\n",
            "Collecting protobuf==4.24.1 (from -r requirements.txt (line 67))\n",
            "  Downloading protobuf-4.24.1-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil==5.9.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 68)) (5.9.5)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 69)) (0.7.0)\n",
            "Collecting pure-eval==0.2.2 (from -r requirements.txt (line 70))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyasn1==0.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 71)) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 72)) (0.3.0)\n",
            "Requirement already satisfied: pydot==1.4.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 73)) (1.4.2)\n",
            "Requirement already satisfied: Pygments==2.16.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 74)) (2.16.1)\n",
            "Collecting pyparsing==3.0.9 (from -r requirements.txt (line 75))\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 76)) (2.8.2)\n",
            "Requirement already satisfied: pytz==2023.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 77)) (2023.3)\n",
            "Collecting pyzmq==25.1.1 (from -r requirements.txt (line 78))\n",
            "  Downloading pyzmq-25.1.1-cp310-cp310-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: referencing==0.30.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 79)) (0.30.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 80)) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 81)) (1.3.1)\n",
            "Requirement already satisfied: rpds-py==0.9.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 82)) (0.9.2)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 83)) (4.9)\n",
            "Collecting scikit-learn==1.3.0 (from -r requirements.txt (line 84))\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.11.2 (from -r requirements.txt (line 85))\n",
            "  Downloading scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 86)) (1.16.0)\n",
            "Requirement already satisfied: soupsieve==2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 87)) (2.4.1)\n",
            "Collecting stack-data==0.6.2 (from -r requirements.txt (line 88))\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting tensorboard==2.13.0 (from -r requirements.txt (line 89))\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-data-server==0.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 90)) (0.7.1)\n",
            "Collecting tensorflow==2.13.0 (from -r requirements.txt (line 91))\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator==2.13.0 (from -r requirements.txt (line 92))\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.33.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 93)) (0.33.0)\n",
            "Collecting tensorrt==8.6.1 (from -r requirements.txt (line 94))\n",
            "  Downloading tensorrt-8.6.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt-bindings==8.6.1 (from -r requirements.txt (line 95))\n",
            "  Downloading tensorrt_bindings-8.6.1-cp310-none-manylinux_2_17_x86_64.whl (979 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.4/979.4 kB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorrt-libs==8.6.1 (from -r requirements.txt (line 96))\n",
            "  Downloading tensorrt-libs-8.6.1.tar.gz (6.8 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "cP_EGwT78glL",
        "outputId": "c1d8bb2b-0fdc-4fdb-a643-994a0d1bb7ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-21 23:29:11.363443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-21 23:29:12.499443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-21 23:29:15.067388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-21 23:29:15.068609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-21 23:29:15.069572: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-21 23:29:15.222045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-21 23:29:15.223651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-21 23:29:15.224677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "Epoch 1/600\n",
            "2023-08-21 23:29:15.537335: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-21 23:29:15.538517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-21 23:29:15.539861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-21 23:29:15.859304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-21 23:29:15.860388: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-21 23:29:15.861405: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-21 23:29:16.633830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-21 23:29:16.634906: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-21 23:29:16.635994: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-21 23:29:16.783709: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-21 23:29:16.784861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-21 23:29:16.785866: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "1120/1121 [============================>.] - ETA: 0s - loss: 0.0161 - mape: 1369768.87502023-08-21 23:29:30.053189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-21 23:29:30.054215: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-21 23:29:30.055157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-21 23:29:30.207862: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-21 23:29:30.208952: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-21 23:29:30.210036: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "1121/1121 [==============================] - 15s 11ms/step - loss: 0.0161 - mape: 1369711.6250 - val_loss: 0.0144 - val_mape: 1292911.8750\n",
            "Epoch 2/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0147 - mape: 1234189.1250 - val_loss: 0.0142 - val_mape: 1279407.5000\n",
            "Epoch 3/600\n",
            "1121/1121 [==============================] - 14s 12ms/step - loss: 0.0142 - mape: 1187169.0000 - val_loss: 0.0130 - val_mape: 1077990.6250\n",
            "Epoch 4/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0110 - mape: 874358.0625 - val_loss: 0.0099 - val_mape: 530096.5000\n",
            "Epoch 5/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0097 - mape: 603777.7500 - val_loss: 0.0084 - val_mape: 586920.5000\n",
            "Epoch 6/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0094 - mape: 572465.1250 - val_loss: 0.0091 - val_mape: 682071.1875\n",
            "Epoch 7/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0093 - mape: 551747.1875 - val_loss: 0.0091 - val_mape: 474376.0000\n",
            "Epoch 8/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0092 - mape: 538067.9375 - val_loss: 0.0162 - val_mape: 899462.8750\n",
            "Epoch 9/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0091 - mape: 536465.0625 - val_loss: 0.0185 - val_mape: 952048.3125\n",
            "Epoch 10/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0090 - mape: 529171.7500 - val_loss: 0.0088 - val_mape: 608792.3750\n",
            "Epoch 11/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0090 - mape: 520776.2500 - val_loss: 0.0089 - val_mape: 463352.8438\n",
            "Epoch 12/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0090 - mape: 521004.1875 - val_loss: 0.0100 - val_mape: 693221.0625\n",
            "Epoch 13/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0089 - mape: 513428.1562 - val_loss: 0.0087 - val_mape: 466975.8125\n",
            "Epoch 14/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0089 - mape: 514024.5938 - val_loss: 0.0143 - val_mape: 813105.5000\n",
            "Epoch 15/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0089 - mape: 510465.2188 - val_loss: 0.0084 - val_mape: 505552.1250\n",
            "Epoch 16/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0089 - mape: 503143.2188 - val_loss: 0.0090 - val_mape: 427792.4688\n",
            "Epoch 17/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0089 - mape: 502147.7188 - val_loss: 0.0089 - val_mape: 429516.5000\n",
            "Epoch 18/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0088 - mape: 498510.8438 - val_loss: 0.0110 - val_mape: 343905.0000\n",
            "Epoch 19/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0088 - mape: 498318.9062 - val_loss: 0.0086 - val_mape: 574083.4375\n",
            "Epoch 20/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0088 - mape: 494750.2500 - val_loss: 0.0083 - val_mape: 517058.6562\n",
            "Epoch 21/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0088 - mape: 493709.9062 - val_loss: 0.0089 - val_mape: 426476.2188\n",
            "Epoch 22/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0088 - mape: 489870.3438 - val_loss: 0.0085 - val_mape: 549831.8750\n",
            "Epoch 23/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0088 - mape: 485883.2500 - val_loss: 0.0083 - val_mape: 502175.1875\n",
            "Epoch 24/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0088 - mape: 488372.5938 - val_loss: 0.0090 - val_mape: 392401.3125\n",
            "Epoch 25/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0087 - mape: 480594.5000 - val_loss: 0.0092 - val_mape: 391494.1562\n",
            "Epoch 26/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0087 - mape: 478703.6250 - val_loss: 0.0084 - val_mape: 468695.6250\n",
            "Epoch 27/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0087 - mape: 477396.4375 - val_loss: 0.0092 - val_mape: 623565.7500\n",
            "Epoch 28/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0087 - mape: 474312.0000 - val_loss: 0.0085 - val_mape: 433120.9688\n",
            "Epoch 29/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0087 - mape: 471526.6875 - val_loss: 0.0083 - val_mape: 519744.8125\n",
            "Epoch 30/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0087 - mape: 465662.4062 - val_loss: 0.0087 - val_mape: 556033.5000\n",
            "Epoch 31/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0087 - mape: 461911.1562 - val_loss: 0.0088 - val_mape: 555980.0000\n",
            "Epoch 32/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0086 - mape: 458115.1250 - val_loss: 0.0082 - val_mape: 494284.8125\n",
            "Epoch 33/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0086 - mape: 449228.1250 - val_loss: 0.0087 - val_mape: 557844.0625\n",
            "Epoch 34/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0085 - mape: 442165.3125 - val_loss: 0.0090 - val_mape: 333530.1250\n",
            "Epoch 35/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0085 - mape: 425817.8438 - val_loss: 0.0084 - val_mape: 505841.9062\n",
            "Epoch 36/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0083 - mape: 408833.6875 - val_loss: 0.0077 - val_mape: 404431.3125\n",
            "Epoch 37/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0081 - mape: 388853.5000 - val_loss: 0.0076 - val_mape: 415504.9062\n",
            "Epoch 38/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0080 - mape: 373570.0312 - val_loss: 0.0074 - val_mape: 387567.6250\n",
            "Epoch 39/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0079 - mape: 386152.4062 - val_loss: 0.0073 - val_mape: 360716.5000\n",
            "Epoch 40/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0077 - mape: 391242.9688 - val_loss: 0.0073 - val_mape: 396890.4062\n",
            "Epoch 41/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0077 - mape: 393251.8125 - val_loss: 0.0072 - val_mape: 367218.8750\n",
            "Epoch 42/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0076 - mape: 393791.3750 - val_loss: 0.0074 - val_mape: 423584.0938\n",
            "Epoch 43/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0075 - mape: 389391.3125 - val_loss: 0.0071 - val_mape: 399348.7812\n",
            "Epoch 44/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0075 - mape: 381211.3125 - val_loss: 0.0071 - val_mape: 392771.5000\n",
            "Epoch 45/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0075 - mape: 383699.9375 - val_loss: 0.0070 - val_mape: 380659.7500\n",
            "Epoch 46/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0075 - mape: 382038.9688 - val_loss: 0.0075 - val_mape: 450367.8438\n",
            "Epoch 47/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0075 - mape: 381156.5312 - val_loss: 0.0074 - val_mape: 345363.9688\n",
            "Epoch 48/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0075 - mape: 378243.8125 - val_loss: 0.0072 - val_mape: 418342.3750\n",
            "Epoch 49/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 378962.4688 - val_loss: 0.0072 - val_mape: 418121.3438\n",
            "Epoch 50/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 372392.5000 - val_loss: 0.0070 - val_mape: 378663.2188\n",
            "Epoch 51/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 375976.0625 - val_loss: 0.0070 - val_mape: 391916.5625\n",
            "Epoch 52/600\n",
            "1121/1121 [==============================] - 14s 13ms/step - loss: 0.0074 - mape: 377647.2188 - val_loss: 0.0070 - val_mape: 363374.1250\n",
            "Epoch 53/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 375069.3750 - val_loss: 0.0070 - val_mape: 382945.9688\n",
            "Epoch 54/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 371935.3125 - val_loss: 0.0070 - val_mape: 380521.5000\n",
            "Epoch 55/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0074 - mape: 371405.7188 - val_loss: 0.0071 - val_mape: 426723.3125\n",
            "Epoch 56/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 371890.5000 - val_loss: 0.0070 - val_mape: 366418.2812\n",
            "Epoch 57/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 372095.0000 - val_loss: 0.0070 - val_mape: 371959.6562\n",
            "Epoch 58/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 372223.4062 - val_loss: 0.0070 - val_mape: 370048.3438\n",
            "Epoch 59/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 371480.1250 - val_loss: 0.0070 - val_mape: 413039.3750\n",
            "Epoch 60/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 372257.0312 - val_loss: 0.0072 - val_mape: 414808.5000\n",
            "Epoch 61/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 371457.1250 - val_loss: 0.0070 - val_mape: 386966.5000\n",
            "Epoch 62/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369683.2812 - val_loss: 0.0074 - val_mape: 314583.9688\n",
            "Epoch 63/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369887.4062 - val_loss: 0.0070 - val_mape: 348689.0938\n",
            "Epoch 64/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 371957.8750 - val_loss: 0.0071 - val_mape: 393307.1250\n",
            "Epoch 65/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369657.8750 - val_loss: 0.0071 - val_mape: 416920.0312\n",
            "Epoch 66/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369019.6562 - val_loss: 0.0070 - val_mape: 366123.7188\n",
            "Epoch 67/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 368555.5625 - val_loss: 0.0070 - val_mape: 395014.0938\n",
            "Epoch 68/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 370116.3125 - val_loss: 0.0073 - val_mape: 436321.0938\n",
            "Epoch 69/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 368721.2500 - val_loss: 0.0070 - val_mape: 396223.3125\n",
            "Epoch 70/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369559.5938 - val_loss: 0.0070 - val_mape: 409515.1250\n",
            "Epoch 71/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 370927.6875 - val_loss: 0.0071 - val_mape: 414321.4062\n",
            "Epoch 72/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369788.4375 - val_loss: 0.0071 - val_mape: 399475.6250\n",
            "Epoch 73/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369775.9375 - val_loss: 0.0070 - val_mape: 360529.5312\n",
            "Epoch 74/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369328.4062 - val_loss: 0.0070 - val_mape: 357482.9375\n",
            "Epoch 75/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 366345.3750 - val_loss: 0.0070 - val_mape: 367151.9688\n",
            "Epoch 76/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 368256.5000 - val_loss: 0.0070 - val_mape: 401319.2188\n",
            "Epoch 77/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 366678.1250 - val_loss: 0.0072 - val_mape: 339374.4688\n",
            "Epoch 78/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 366647.5000 - val_loss: 0.0070 - val_mape: 380019.8750\n",
            "Epoch 79/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 367394.3438 - val_loss: 0.0071 - val_mape: 412465.6875\n",
            "Epoch 80/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 366682.1562 - val_loss: 0.0070 - val_mape: 370209.9062\n",
            "Epoch 81/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 368448.0938 - val_loss: 0.0071 - val_mape: 409915.9062\n",
            "Epoch 82/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 369915.9688 - val_loss: 0.0070 - val_mape: 367449.8438\n",
            "Epoch 83/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 368557.8125 - val_loss: 0.0072 - val_mape: 332045.5312\n",
            "Epoch 84/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0074 - mape: 368656.0312 - val_loss: 0.0070 - val_mape: 371904.3125\n",
            "Epoch 85/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 368472.3750 - val_loss: 0.0071 - val_mape: 400075.0312\n",
            "Epoch 86/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0074 - mape: 366565.5938 - val_loss: 0.0071 - val_mape: 351176.8438\n",
            "Epoch 87/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0074 - mape: 365753.1250 - val_loss: 0.0072 - val_mape: 333297.8438\n",
            "Epoch 88/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369330.9688 - val_loss: 0.0070 - val_mape: 379640.4375\n",
            "Epoch 89/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 367667.5938 - val_loss: 0.0070 - val_mape: 381311.4688\n",
            "Epoch 90/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 366386.3125 - val_loss: 0.0070 - val_mape: 353626.5000\n",
            "Epoch 91/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 367563.8438 - val_loss: 0.0072 - val_mape: 336358.5938\n",
            "Epoch 92/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 366318.4062 - val_loss: 0.0070 - val_mape: 395962.2812\n",
            "Epoch 93/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 365670.0625 - val_loss: 0.0070 - val_mape: 396466.6562\n",
            "Epoch 94/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 367973.1250 - val_loss: 0.0070 - val_mape: 350285.6250\n",
            "Epoch 95/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 369126.1250 - val_loss: 0.0071 - val_mape: 421367.1875\n",
            "Epoch 96/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 368682.8750 - val_loss: 0.0071 - val_mape: 413225.7188\n",
            "Epoch 97/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 367400.6562 - val_loss: 0.0070 - val_mape: 347437.2188\n",
            "Epoch 98/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0074 - mape: 367667.8438 - val_loss: 0.0070 - val_mape: 354052.5312\n",
            "Epoch 99/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 366353.0312 - val_loss: 0.0071 - val_mape: 342552.0625\n",
            "Epoch 100/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 367934.6250 - val_loss: 0.0070 - val_mape: 387249.6875\n",
            "Epoch 101/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 367077.7500 - val_loss: 0.0070 - val_mape: 390035.8125\n",
            "Epoch 102/600\n",
            "1121/1121 [==============================] - 14s 12ms/step - loss: 0.0073 - mape: 364206.2500 - val_loss: 0.0070 - val_mape: 373354.3750\n",
            "Epoch 103/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0074 - mape: 367093.3125 - val_loss: 0.0071 - val_mape: 350256.4375\n",
            "Epoch 104/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 367967.4375 - val_loss: 0.0070 - val_mape: 367994.8125\n",
            "Epoch 105/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 366702.2188 - val_loss: 0.0070 - val_mape: 375510.3438\n",
            "Epoch 106/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0074 - mape: 366888.3125 - val_loss: 0.0070 - val_mape: 383945.4062\n",
            "Epoch 107/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 367949.2188 - val_loss: 0.0070 - val_mape: 367316.8750\n",
            "Epoch 108/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 367165.3750 - val_loss: 0.0070 - val_mape: 349222.8750\n",
            "Epoch 109/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 368452.7188 - val_loss: 0.0070 - val_mape: 376462.3125\n",
            "Epoch 110/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 367988.8125 - val_loss: 0.0071 - val_mape: 403791.9688\n",
            "Epoch 111/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 368655.2188 - val_loss: 0.0070 - val_mape: 366390.3750\n",
            "Epoch 112/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 368601.7500 - val_loss: 0.0070 - val_mape: 368918.8750\n",
            "Epoch 113/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 365056.7812 - val_loss: 0.0070 - val_mape: 403182.8750\n",
            "Epoch 114/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0073 - mape: 367690.5000 - val_loss: 0.0070 - val_mape: 396451.0000\n",
            "Epoch 115/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 367826.9375 - val_loss: 0.0073 - val_mape: 305775.2188\n",
            "Epoch 116/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 371364.6562 - val_loss: 0.0070 - val_mape: 374788.4688\n",
            "Epoch 117/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 369678.1250 - val_loss: 0.0071 - val_mape: 368934.0000\n",
            "Epoch 118/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 368725.4688 - val_loss: 0.0070 - val_mape: 358289.0000\n",
            "Epoch 119/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 372853.2812 - val_loss: 0.0070 - val_mape: 364118.9688\n",
            "Epoch 120/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 370556.3125 - val_loss: 0.0071 - val_mape: 412876.7812\n",
            "Epoch 121/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 370297.8750 - val_loss: 0.0070 - val_mape: 399657.5938\n",
            "Epoch 122/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 370106.3125 - val_loss: 0.0070 - val_mape: 360346.4375\n",
            "Epoch 123/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 368891.9688 - val_loss: 0.0070 - val_mape: 382221.5625\n",
            "Epoch 124/600\n",
            "1121/1121 [==============================] - 14s 12ms/step - loss: 0.0073 - mape: 370749.1875 - val_loss: 0.0071 - val_mape: 339662.8750\n",
            "Epoch 125/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 370022.0312 - val_loss: 0.0070 - val_mape: 381605.0312\n",
            "Epoch 126/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0073 - mape: 370699.2500 - val_loss: 0.0071 - val_mape: 346401.5625\n",
            "Epoch 127/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 370607.7812 - val_loss: 0.0071 - val_mape: 352896.5312\n",
            "Epoch 128/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 369512.4375 - val_loss: 0.0070 - val_mape: 368148.9062\n",
            "Epoch 129/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 372406.3750 - val_loss: 0.0070 - val_mape: 404237.6250\n",
            "Epoch 130/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 369921.7812 - val_loss: 0.0070 - val_mape: 367719.1250\n",
            "Epoch 131/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 370363.1250 - val_loss: 0.0070 - val_mape: 357969.2812\n",
            "Epoch 132/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 372373.2812 - val_loss: 0.0069 - val_mape: 358070.4375\n",
            "Epoch 133/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 371608.3750 - val_loss: 0.0071 - val_mape: 429742.5938\n",
            "Epoch 134/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 372459.8438 - val_loss: 0.0071 - val_mape: 431411.6250\n",
            "Epoch 135/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 368260.3438 - val_loss: 0.0070 - val_mape: 380209.6875\n",
            "Epoch 136/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 371216.7812 - val_loss: 0.0071 - val_mape: 353908.8438\n",
            "Epoch 137/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0073 - mape: 370582.5625 - val_loss: 0.0071 - val_mape: 398779.6250\n",
            "Epoch 138/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 372033.0312 - val_loss: 0.0070 - val_mape: 394559.4688\n",
            "Epoch 139/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 372057.8438 - val_loss: 0.0070 - val_mape: 373161.3438\n",
            "Epoch 140/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 370276.9375 - val_loss: 0.0070 - val_mape: 345275.2188\n",
            "Epoch 141/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 371082.2500 - val_loss: 0.0070 - val_mape: 360792.5000\n",
            "Epoch 142/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 371321.0625 - val_loss: 0.0071 - val_mape: 375735.4375\n",
            "Epoch 143/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 372216.2500 - val_loss: 0.0070 - val_mape: 350325.6562\n",
            "Epoch 144/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 370021.3125 - val_loss: 0.0069 - val_mape: 379073.7500\n",
            "Epoch 145/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 370481.1250 - val_loss: 0.0070 - val_mape: 405695.5625\n",
            "Epoch 146/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 369734.9375 - val_loss: 0.0071 - val_mape: 331303.0000\n",
            "Epoch 147/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 369358.4062 - val_loss: 0.0070 - val_mape: 423127.1875\n",
            "Epoch 148/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 370801.6250 - val_loss: 0.0070 - val_mape: 414618.4688\n",
            "Epoch 149/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 371014.0312 - val_loss: 0.0071 - val_mape: 353365.1562\n",
            "Epoch 150/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 368831.2500 - val_loss: 0.0070 - val_mape: 345174.9062\n",
            "Epoch 151/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 369767.6250 - val_loss: 0.0071 - val_mape: 431708.8750\n",
            "Epoch 152/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 368532.8750 - val_loss: 0.0070 - val_mape: 373180.7812\n",
            "Epoch 153/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 366743.1562 - val_loss: 0.0070 - val_mape: 400003.2500\n",
            "Epoch 154/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 369093.2500 - val_loss: 0.0069 - val_mape: 375709.9375\n",
            "Epoch 155/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 368018.2812 - val_loss: 0.0070 - val_mape: 405968.6250\n",
            "Epoch 156/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 368201.7188 - val_loss: 0.0071 - val_mape: 423699.0938\n",
            "Epoch 157/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 366151.2188 - val_loss: 0.0070 - val_mape: 360664.7500\n",
            "Epoch 158/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 366773.1562 - val_loss: 0.0071 - val_mape: 405184.2188\n",
            "Epoch 159/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 364804.4688 - val_loss: 0.0070 - val_mape: 371063.7500\n",
            "Epoch 160/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 365258.3125 - val_loss: 0.0070 - val_mape: 411112.9375\n",
            "Epoch 161/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 363700.9062 - val_loss: 0.0071 - val_mape: 415302.9688\n",
            "Epoch 162/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 365579.1250 - val_loss: 0.0069 - val_mape: 390012.9062\n",
            "Epoch 163/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 367153.7500 - val_loss: 0.0070 - val_mape: 382072.5938\n",
            "Epoch 164/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 365988.5000 - val_loss: 0.0072 - val_mape: 431146.0312\n",
            "Epoch 165/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 365703.0625 - val_loss: 0.0069 - val_mape: 366825.0000\n",
            "Epoch 166/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 363098.5312 - val_loss: 0.0070 - val_mape: 356511.1250\n",
            "Epoch 167/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 363770.3125 - val_loss: 0.0070 - val_mape: 401229.0938\n",
            "Epoch 168/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 366418.0938 - val_loss: 0.0070 - val_mape: 351015.2500\n",
            "Epoch 169/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 365361.7812 - val_loss: 0.0070 - val_mape: 355068.8125\n",
            "Epoch 170/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 363458.0312 - val_loss: 0.0070 - val_mape: 405201.6875\n",
            "Epoch 171/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 364196.0625 - val_loss: 0.0072 - val_mape: 446115.0000\n",
            "Epoch 172/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 363405.6562 - val_loss: 0.0069 - val_mape: 360623.6562\n",
            "Epoch 173/600\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0073 - mape: 364651.0312 - val_loss: 0.0070 - val_mape: 405631.1562\n",
            "Epoch 174/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 362206.1875 - val_loss: 0.0070 - val_mape: 356324.1875\n",
            "Epoch 175/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 363997.1562 - val_loss: 0.0070 - val_mape: 347585.8750\n",
            "Epoch 176/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 364689.7500 - val_loss: 0.0070 - val_mape: 388523.6250\n",
            "Epoch 177/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 361794.9062 - val_loss: 0.0070 - val_mape: 374957.6250\n",
            "Epoch 178/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 363358.6875 - val_loss: 0.0069 - val_mape: 363070.2188\n",
            "Epoch 179/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 361142.0625 - val_loss: 0.0070 - val_mape: 355767.8438\n",
            "Epoch 180/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 359876.5000 - val_loss: 0.0070 - val_mape: 384966.0938\n",
            "Epoch 181/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 359896.1250 - val_loss: 0.0070 - val_mape: 345788.3125\n",
            "Epoch 182/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 362973.3125 - val_loss: 0.0069 - val_mape: 385918.8750\n",
            "Epoch 183/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 359662.7812 - val_loss: 0.0069 - val_mape: 380363.1875\n",
            "Epoch 184/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 360129.0000 - val_loss: 0.0069 - val_mape: 388650.6875\n",
            "Epoch 185/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 359595.8750 - val_loss: 0.0070 - val_mape: 350873.8438\n",
            "Epoch 186/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 360772.5000 - val_loss: 0.0070 - val_mape: 375508.3125\n",
            "Epoch 187/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 358886.6250 - val_loss: 0.0069 - val_mape: 372152.5625\n",
            "Epoch 188/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 360500.8438 - val_loss: 0.0070 - val_mape: 330879.5938\n",
            "Epoch 189/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 359573.6250 - val_loss: 0.0070 - val_mape: 354809.8750\n",
            "Epoch 190/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 360167.1875 - val_loss: 0.0070 - val_mape: 346061.1562\n",
            "Epoch 191/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 360340.9062 - val_loss: 0.0070 - val_mape: 399787.7500\n",
            "Epoch 192/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 358161.1875 - val_loss: 0.0070 - val_mape: 395114.8438\n",
            "Epoch 193/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 359676.0312 - val_loss: 0.0071 - val_mape: 328755.9688\n",
            "Epoch 194/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 358576.7812 - val_loss: 0.0070 - val_mape: 404322.3125\n",
            "Epoch 195/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 358893.3750 - val_loss: 0.0070 - val_mape: 364761.0000\n",
            "Epoch 196/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 359384.8750 - val_loss: 0.0071 - val_mape: 398709.5312\n",
            "Epoch 197/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 359262.5625 - val_loss: 0.0069 - val_mape: 357633.9688\n",
            "Epoch 198/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 358462.5000 - val_loss: 0.0070 - val_mape: 404144.2812\n",
            "Epoch 199/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357171.4688 - val_loss: 0.0070 - val_mape: 334459.4688\n",
            "Epoch 200/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 358107.3750 - val_loss: 0.0069 - val_mape: 362405.4062\n",
            "Epoch 201/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 360083.7812 - val_loss: 0.0071 - val_mape: 389386.7812\n",
            "Epoch 202/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357106.3750 - val_loss: 0.0069 - val_mape: 374686.2500\n",
            "Epoch 203/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 358725.1875 - val_loss: 0.0069 - val_mape: 383342.9688\n",
            "Epoch 204/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 358172.8438 - val_loss: 0.0070 - val_mape: 387232.3438\n",
            "Epoch 205/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357559.6562 - val_loss: 0.0070 - val_mape: 353480.0938\n",
            "Epoch 206/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 359087.1562 - val_loss: 0.0069 - val_mape: 388339.9688\n",
            "Epoch 207/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356889.9062 - val_loss: 0.0070 - val_mape: 367244.2188\n",
            "Epoch 208/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357180.1250 - val_loss: 0.0069 - val_mape: 345657.0312\n",
            "Epoch 209/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 356854.1875 - val_loss: 0.0070 - val_mape: 385612.4688\n",
            "Epoch 210/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 358002.6875 - val_loss: 0.0071 - val_mape: 409408.1875\n",
            "Epoch 211/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357115.3125 - val_loss: 0.0070 - val_mape: 339750.0312\n",
            "Epoch 212/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 355636.4375 - val_loss: 0.0070 - val_mape: 378609.0938\n",
            "Epoch 213/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 358839.2812 - val_loss: 0.0070 - val_mape: 401835.6562\n",
            "Epoch 214/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357530.3125 - val_loss: 0.0070 - val_mape: 388864.2500\n",
            "Epoch 215/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357885.4062 - val_loss: 0.0070 - val_mape: 346117.5625\n",
            "Epoch 216/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356327.2188 - val_loss: 0.0070 - val_mape: 386405.9062\n",
            "Epoch 217/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 358056.0312 - val_loss: 0.0070 - val_mape: 372015.8125\n",
            "Epoch 218/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 356596.7188 - val_loss: 0.0069 - val_mape: 366854.6875\n",
            "Epoch 219/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354783.0625 - val_loss: 0.0069 - val_mape: 394548.4688\n",
            "Epoch 220/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 358357.9375 - val_loss: 0.0070 - val_mape: 371990.8750\n",
            "Epoch 221/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356923.2500 - val_loss: 0.0070 - val_mape: 394996.0938\n",
            "Epoch 222/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356496.9062 - val_loss: 0.0071 - val_mape: 341630.7188\n",
            "Epoch 223/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357685.3750 - val_loss: 0.0071 - val_mape: 397979.2500\n",
            "Epoch 224/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357297.2188 - val_loss: 0.0071 - val_mape: 421975.0625\n",
            "Epoch 225/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355164.0938 - val_loss: 0.0070 - val_mape: 397286.4062\n",
            "Epoch 226/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 356039.7188 - val_loss: 0.0071 - val_mape: 328903.0625\n",
            "Epoch 227/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355724.7812 - val_loss: 0.0069 - val_mape: 358328.3125\n",
            "Epoch 228/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356469.8438 - val_loss: 0.0070 - val_mape: 394353.5000\n",
            "Epoch 229/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357775.3125 - val_loss: 0.0069 - val_mape: 355387.8125\n",
            "Epoch 230/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355580.8438 - val_loss: 0.0070 - val_mape: 403042.5625\n",
            "Epoch 231/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355495.4375 - val_loss: 0.0069 - val_mape: 360530.9062\n",
            "Epoch 232/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357338.7812 - val_loss: 0.0069 - val_mape: 355127.9062\n",
            "Epoch 233/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355266.5312 - val_loss: 0.0069 - val_mape: 362141.2500\n",
            "Epoch 234/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 354711.0312 - val_loss: 0.0071 - val_mape: 388287.2500\n",
            "Epoch 235/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355224.9375 - val_loss: 0.0070 - val_mape: 374566.7500\n",
            "Epoch 236/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357535.4062 - val_loss: 0.0070 - val_mape: 348502.6250\n",
            "Epoch 237/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356506.7500 - val_loss: 0.0070 - val_mape: 396995.0625\n",
            "Epoch 238/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357613.8750 - val_loss: 0.0070 - val_mape: 347765.9375\n",
            "Epoch 239/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354545.2500 - val_loss: 0.0069 - val_mape: 352390.4688\n",
            "Epoch 240/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354282.5000 - val_loss: 0.0070 - val_mape: 403452.2812\n",
            "Epoch 241/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 354597.4062 - val_loss: 0.0070 - val_mape: 362254.7500\n",
            "Epoch 242/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 356558.6250 - val_loss: 0.0070 - val_mape: 404641.4375\n",
            "Epoch 243/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357181.0312 - val_loss: 0.0069 - val_mape: 364333.0938\n",
            "Epoch 244/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357179.4688 - val_loss: 0.0070 - val_mape: 385829.9375\n",
            "Epoch 245/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356214.4062 - val_loss: 0.0069 - val_mape: 376001.2188\n",
            "Epoch 246/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357140.8125 - val_loss: 0.0069 - val_mape: 371238.3750\n",
            "Epoch 247/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356386.1875 - val_loss: 0.0070 - val_mape: 394944.1250\n",
            "Epoch 248/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356702.5625 - val_loss: 0.0069 - val_mape: 370806.6250\n",
            "Epoch 249/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357408.0000 - val_loss: 0.0070 - val_mape: 389643.9062\n",
            "Epoch 250/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357477.5938 - val_loss: 0.0070 - val_mape: 357726.0938\n",
            "Epoch 251/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 357354.0000 - val_loss: 0.0069 - val_mape: 362962.6875\n",
            "Epoch 252/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 356613.9375 - val_loss: 0.0069 - val_mape: 360396.0000\n",
            "Epoch 253/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353379.7188 - val_loss: 0.0069 - val_mape: 378983.2500\n",
            "Epoch 254/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356939.2500 - val_loss: 0.0069 - val_mape: 382766.0938\n",
            "Epoch 255/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 356954.7812 - val_loss: 0.0070 - val_mape: 341219.0000\n",
            "Epoch 256/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 356321.0938 - val_loss: 0.0070 - val_mape: 397858.2188\n",
            "Epoch 257/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355952.0312 - val_loss: 0.0070 - val_mape: 380268.6562\n",
            "Epoch 258/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354896.1562 - val_loss: 0.0070 - val_mape: 388298.8750\n",
            "Epoch 259/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355678.7812 - val_loss: 0.0069 - val_mape: 362218.9062\n",
            "Epoch 260/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356837.0312 - val_loss: 0.0069 - val_mape: 351560.0938\n",
            "Epoch 261/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 356312.6875 - val_loss: 0.0070 - val_mape: 375440.7812\n",
            "Epoch 262/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356989.3125 - val_loss: 0.0070 - val_mape: 389070.4062\n",
            "Epoch 263/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355624.7500 - val_loss: 0.0070 - val_mape: 359280.9688\n",
            "Epoch 264/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356661.3438 - val_loss: 0.0069 - val_mape: 373004.2812\n",
            "Epoch 265/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 357033.7500 - val_loss: 0.0070 - val_mape: 350599.5938\n",
            "Epoch 266/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 357435.3125 - val_loss: 0.0070 - val_mape: 352997.2812\n",
            "Epoch 267/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 357083.0000 - val_loss: 0.0070 - val_mape: 392706.6562\n",
            "Epoch 268/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 358919.5938 - val_loss: 0.0069 - val_mape: 380910.1250\n",
            "Epoch 269/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356053.9688 - val_loss: 0.0070 - val_mape: 330151.0625\n",
            "Epoch 270/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355304.4062 - val_loss: 0.0070 - val_mape: 380828.6562\n",
            "Epoch 271/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355687.0625 - val_loss: 0.0070 - val_mape: 396268.4375\n",
            "Epoch 272/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356093.6250 - val_loss: 0.0071 - val_mape: 379297.8438\n",
            "Epoch 273/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355984.5000 - val_loss: 0.0069 - val_mape: 365714.9688\n",
            "Epoch 274/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 355682.8438 - val_loss: 0.0071 - val_mape: 411523.0625\n",
            "Epoch 275/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356294.6875 - val_loss: 0.0070 - val_mape: 365401.3125\n",
            "Epoch 276/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354647.0625 - val_loss: 0.0070 - val_mape: 382221.6875\n",
            "Epoch 277/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355843.0938 - val_loss: 0.0070 - val_mape: 363720.7812\n",
            "Epoch 278/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356505.0000 - val_loss: 0.0070 - val_mape: 348572.5938\n",
            "Epoch 279/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 357045.4062 - val_loss: 0.0069 - val_mape: 357319.0938\n",
            "Epoch 280/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356374.0938 - val_loss: 0.0070 - val_mape: 363224.3750\n",
            "Epoch 281/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 354554.9688 - val_loss: 0.0069 - val_mape: 369560.4062\n",
            "Epoch 282/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355860.1562 - val_loss: 0.0069 - val_mape: 385759.9062\n",
            "Epoch 283/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357953.4062 - val_loss: 0.0069 - val_mape: 346553.2188\n",
            "Epoch 284/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355482.5000 - val_loss: 0.0070 - val_mape: 399614.5625\n",
            "Epoch 285/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355141.7812 - val_loss: 0.0071 - val_mape: 337156.3438\n",
            "Epoch 286/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 357193.5625 - val_loss: 0.0070 - val_mape: 377224.2188\n",
            "Epoch 287/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 355480.8750 - val_loss: 0.0071 - val_mape: 421801.9375\n",
            "Epoch 288/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356041.5000 - val_loss: 0.0069 - val_mape: 375175.9688\n",
            "Epoch 289/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356133.4375 - val_loss: 0.0070 - val_mape: 351224.0312\n",
            "Epoch 290/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355697.8750 - val_loss: 0.0070 - val_mape: 354029.2500\n",
            "Epoch 291/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355501.7500 - val_loss: 0.0069 - val_mape: 357427.8125\n",
            "Epoch 292/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354846.3125 - val_loss: 0.0071 - val_mape: 396424.9688\n",
            "Epoch 293/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355868.1562 - val_loss: 0.0070 - val_mape: 375747.5938\n",
            "Epoch 294/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 353082.9062 - val_loss: 0.0070 - val_mape: 407972.7812\n",
            "Epoch 295/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354825.0625 - val_loss: 0.0070 - val_mape: 395975.1562\n",
            "Epoch 296/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355484.0312 - val_loss: 0.0069 - val_mape: 359053.3438\n",
            "Epoch 297/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355772.8438 - val_loss: 0.0069 - val_mape: 369497.9688\n",
            "Epoch 298/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 356805.8438 - val_loss: 0.0071 - val_mape: 410288.7500\n",
            "Epoch 299/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356240.3438 - val_loss: 0.0070 - val_mape: 374986.8750\n",
            "Epoch 300/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 357939.5000 - val_loss: 0.0069 - val_mape: 344858.9375\n",
            "Epoch 301/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 356422.5312 - val_loss: 0.0070 - val_mape: 377147.7188\n",
            "Epoch 302/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354077.4062 - val_loss: 0.0069 - val_mape: 373772.6875\n",
            "Epoch 303/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355178.5312 - val_loss: 0.0070 - val_mape: 375959.4688\n",
            "Epoch 304/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 354741.2812 - val_loss: 0.0069 - val_mape: 368779.1250\n",
            "Epoch 305/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355134.8750 - val_loss: 0.0069 - val_mape: 354949.5312\n",
            "Epoch 306/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 353785.8438 - val_loss: 0.0072 - val_mape: 425120.1875\n",
            "Epoch 307/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 357171.5938 - val_loss: 0.0069 - val_mape: 384933.0000\n",
            "Epoch 308/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 353475.8438 - val_loss: 0.0070 - val_mape: 381444.6562\n",
            "Epoch 309/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355023.8125 - val_loss: 0.0070 - val_mape: 406808.0938\n",
            "Epoch 310/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 354167.2500 - val_loss: 0.0069 - val_mape: 346140.3750\n",
            "Epoch 311/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 353554.3125 - val_loss: 0.0070 - val_mape: 357357.3750\n",
            "Epoch 312/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356319.2812 - val_loss: 0.0072 - val_mape: 406159.7500\n",
            "Epoch 313/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354118.0938 - val_loss: 0.0070 - val_mape: 365988.2812\n",
            "Epoch 314/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356704.0312 - val_loss: 0.0070 - val_mape: 349097.5312\n",
            "Epoch 315/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 354726.6562 - val_loss: 0.0069 - val_mape: 386086.2188\n",
            "Epoch 316/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356367.8125 - val_loss: 0.0069 - val_mape: 372111.3438\n",
            "Epoch 317/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 356080.9688 - val_loss: 0.0069 - val_mape: 353813.5625\n",
            "Epoch 318/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355138.0938 - val_loss: 0.0070 - val_mape: 340585.9375\n",
            "Epoch 319/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 353665.6250 - val_loss: 0.0070 - val_mape: 380127.2812\n",
            "Epoch 320/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 354362.2188 - val_loss: 0.0070 - val_mape: 368046.0938\n",
            "Epoch 321/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355404.7188 - val_loss: 0.0070 - val_mape: 343945.0000\n",
            "Epoch 322/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355245.6250 - val_loss: 0.0069 - val_mape: 367880.9688\n",
            "Epoch 323/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355059.8125 - val_loss: 0.0069 - val_mape: 385765.5625\n",
            "Epoch 324/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355657.0938 - val_loss: 0.0070 - val_mape: 383624.0000\n",
            "Epoch 325/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355821.4375 - val_loss: 0.0070 - val_mape: 360078.7188\n",
            "Epoch 326/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 355593.6562 - val_loss: 0.0070 - val_mape: 374305.9688\n",
            "Epoch 327/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 353523.2188 - val_loss: 0.0070 - val_mape: 405855.0312\n",
            "Epoch 328/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 353869.6875 - val_loss: 0.0069 - val_mape: 382003.6250\n",
            "Epoch 329/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353230.0625 - val_loss: 0.0070 - val_mape: 385305.7812\n",
            "Epoch 330/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 353853.2500 - val_loss: 0.0069 - val_mape: 382618.4688\n",
            "Epoch 331/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 353376.6875 - val_loss: 0.0070 - val_mape: 390906.9688\n",
            "Epoch 332/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 354439.9062 - val_loss: 0.0070 - val_mape: 352049.5000\n",
            "Epoch 333/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355640.6562 - val_loss: 0.0069 - val_mape: 363901.0000\n",
            "Epoch 334/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 355686.5312 - val_loss: 0.0069 - val_mape: 349834.5625\n",
            "Epoch 335/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353635.8438 - val_loss: 0.0071 - val_mape: 336782.1250\n",
            "Epoch 336/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354196.6562 - val_loss: 0.0069 - val_mape: 360958.6875\n",
            "Epoch 337/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352340.5312 - val_loss: 0.0070 - val_mape: 371006.5625\n",
            "Epoch 338/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 354180.2500 - val_loss: 0.0069 - val_mape: 377235.9688\n",
            "Epoch 339/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 354499.6562 - val_loss: 0.0069 - val_mape: 378374.1875\n",
            "Epoch 340/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 354069.7812 - val_loss: 0.0069 - val_mape: 375285.6250\n",
            "Epoch 341/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 354228.2812 - val_loss: 0.0071 - val_mape: 418498.5938\n",
            "Epoch 342/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355789.0625 - val_loss: 0.0070 - val_mape: 366914.7500\n",
            "Epoch 343/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353762.5000 - val_loss: 0.0070 - val_mape: 344214.1875\n",
            "Epoch 344/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353128.9062 - val_loss: 0.0069 - val_mape: 368831.1250\n",
            "Epoch 345/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352994.2188 - val_loss: 0.0070 - val_mape: 346718.1562\n",
            "Epoch 346/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353665.2500 - val_loss: 0.0070 - val_mape: 389694.3750\n",
            "Epoch 347/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 354113.2812 - val_loss: 0.0070 - val_mape: 389480.1250\n",
            "Epoch 348/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354041.5625 - val_loss: 0.0069 - val_mape: 386550.3438\n",
            "Epoch 349/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 352588.6875 - val_loss: 0.0070 - val_mape: 369868.0938\n",
            "Epoch 350/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352141.6875 - val_loss: 0.0072 - val_mape: 406303.5625\n",
            "Epoch 351/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 352629.5000 - val_loss: 0.0069 - val_mape: 381448.1875\n",
            "Epoch 352/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353527.5625 - val_loss: 0.0070 - val_mape: 341443.8750\n",
            "Epoch 353/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352313.3125 - val_loss: 0.0069 - val_mape: 359183.0938\n",
            "Epoch 354/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353360.9375 - val_loss: 0.0070 - val_mape: 339543.3438\n",
            "Epoch 355/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 354174.3438 - val_loss: 0.0069 - val_mape: 380764.0000\n",
            "Epoch 356/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351288.5625 - val_loss: 0.0070 - val_mape: 356934.8125\n",
            "Epoch 357/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353723.8750 - val_loss: 0.0070 - val_mape: 375165.5625\n",
            "Epoch 358/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 355617.8125 - val_loss: 0.0069 - val_mape: 372697.4375\n",
            "Epoch 359/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353880.0312 - val_loss: 0.0070 - val_mape: 365937.4688\n",
            "Epoch 360/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353611.6562 - val_loss: 0.0069 - val_mape: 336240.7812\n",
            "Epoch 361/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351523.2500 - val_loss: 0.0070 - val_mape: 339407.6250\n",
            "Epoch 362/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353032.0000 - val_loss: 0.0070 - val_mape: 344177.5938\n",
            "Epoch 363/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352321.3750 - val_loss: 0.0069 - val_mape: 357979.3125\n",
            "Epoch 364/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353068.4375 - val_loss: 0.0069 - val_mape: 366875.3438\n",
            "Epoch 365/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351641.6875 - val_loss: 0.0069 - val_mape: 358489.8750\n",
            "Epoch 366/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353643.4375 - val_loss: 0.0070 - val_mape: 364071.8750\n",
            "Epoch 367/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 355151.8438 - val_loss: 0.0070 - val_mape: 339962.5312\n",
            "Epoch 368/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353624.4375 - val_loss: 0.0069 - val_mape: 380728.5312\n",
            "Epoch 369/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352117.9688 - val_loss: 0.0069 - val_mape: 376777.8750\n",
            "Epoch 370/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351748.6250 - val_loss: 0.0069 - val_mape: 358750.0000\n",
            "Epoch 371/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352540.0938 - val_loss: 0.0070 - val_mape: 368078.2500\n",
            "Epoch 372/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352297.4062 - val_loss: 0.0069 - val_mape: 366716.0000\n",
            "Epoch 373/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352953.7188 - val_loss: 0.0069 - val_mape: 366856.0938\n",
            "Epoch 374/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352662.0938 - val_loss: 0.0069 - val_mape: 348411.0625\n",
            "Epoch 375/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352511.6562 - val_loss: 0.0069 - val_mape: 373370.7500\n",
            "Epoch 376/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354887.3750 - val_loss: 0.0069 - val_mape: 393033.7812\n",
            "Epoch 377/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353539.6875 - val_loss: 0.0069 - val_mape: 369953.6250\n",
            "Epoch 378/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354013.9688 - val_loss: 0.0069 - val_mape: 352476.3438\n",
            "Epoch 379/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353211.7500 - val_loss: 0.0069 - val_mape: 352721.5625\n",
            "Epoch 380/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353323.7812 - val_loss: 0.0070 - val_mape: 372707.1562\n",
            "Epoch 381/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352576.9688 - val_loss: 0.0069 - val_mape: 349647.5625\n",
            "Epoch 382/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351666.2500 - val_loss: 0.0071 - val_mape: 399752.7500\n",
            "Epoch 383/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351782.2500 - val_loss: 0.0069 - val_mape: 381014.0625\n",
            "Epoch 384/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 354199.4688 - val_loss: 0.0069 - val_mape: 341793.6562\n",
            "Epoch 385/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351483.6562 - val_loss: 0.0069 - val_mape: 353107.5938\n",
            "Epoch 386/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353788.8750 - val_loss: 0.0070 - val_mape: 400724.0000\n",
            "Epoch 387/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352911.5938 - val_loss: 0.0069 - val_mape: 383945.0000\n",
            "Epoch 388/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352533.0625 - val_loss: 0.0070 - val_mape: 402211.6875\n",
            "Epoch 389/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354302.8438 - val_loss: 0.0070 - val_mape: 367096.9375\n",
            "Epoch 390/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351472.4375 - val_loss: 0.0069 - val_mape: 365692.7812\n",
            "Epoch 391/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 354640.6875 - val_loss: 0.0069 - val_mape: 356891.7188\n",
            "Epoch 392/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352331.8438 - val_loss: 0.0069 - val_mape: 350590.0312\n",
            "Epoch 393/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352730.5000 - val_loss: 0.0069 - val_mape: 344073.3750\n",
            "Epoch 394/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353442.1875 - val_loss: 0.0070 - val_mape: 348645.5000\n",
            "Epoch 395/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353580.8750 - val_loss: 0.0069 - val_mape: 341570.3438\n",
            "Epoch 396/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352994.1875 - val_loss: 0.0070 - val_mape: 344616.8125\n",
            "Epoch 397/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352387.2812 - val_loss: 0.0070 - val_mape: 404109.4062\n",
            "Epoch 398/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351560.0625 - val_loss: 0.0070 - val_mape: 338098.9688\n",
            "Epoch 399/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351433.1875 - val_loss: 0.0071 - val_mape: 316376.5000\n",
            "Epoch 400/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350384.3125 - val_loss: 0.0069 - val_mape: 347113.1875\n",
            "Epoch 401/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 349224.7812 - val_loss: 0.0069 - val_mape: 375597.1562\n",
            "Epoch 402/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352401.0000 - val_loss: 0.0070 - val_mape: 365005.8125\n",
            "Epoch 403/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0073 - mape: 351082.3125 - val_loss: 0.0070 - val_mape: 342239.5938\n",
            "Epoch 404/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351607.6250 - val_loss: 0.0069 - val_mape: 366822.1250\n",
            "Epoch 405/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353052.4688 - val_loss: 0.0069 - val_mape: 363246.9688\n",
            "Epoch 406/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352397.8125 - val_loss: 0.0070 - val_mape: 413482.6562\n",
            "Epoch 407/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353276.9375 - val_loss: 0.0070 - val_mape: 403107.1562\n",
            "Epoch 408/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353188.6562 - val_loss: 0.0070 - val_mape: 400147.6875\n",
            "Epoch 409/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350570.4688 - val_loss: 0.0069 - val_mape: 366340.8750\n",
            "Epoch 410/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353569.2188 - val_loss: 0.0069 - val_mape: 360860.2188\n",
            "Epoch 411/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352105.6562 - val_loss: 0.0070 - val_mape: 375811.5625\n",
            "Epoch 412/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 352752.3125 - val_loss: 0.0070 - val_mape: 378599.5000\n",
            "Epoch 413/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351375.9688 - val_loss: 0.0071 - val_mape: 409815.9688\n",
            "Epoch 414/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352117.7812 - val_loss: 0.0069 - val_mape: 347486.8125\n",
            "Epoch 415/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351536.9375 - val_loss: 0.0069 - val_mape: 364829.9375\n",
            "Epoch 416/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351533.7812 - val_loss: 0.0069 - val_mape: 380567.4375\n",
            "Epoch 417/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351488.9375 - val_loss: 0.0069 - val_mape: 354714.8438\n",
            "Epoch 418/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351389.0625 - val_loss: 0.0069 - val_mape: 367804.7188\n",
            "Epoch 419/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352710.3750 - val_loss: 0.0069 - val_mape: 370461.7188\n",
            "Epoch 420/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351004.6562 - val_loss: 0.0070 - val_mape: 375626.4062\n",
            "Epoch 421/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352183.1250 - val_loss: 0.0070 - val_mape: 390641.2812\n",
            "Epoch 422/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352239.4375 - val_loss: 0.0069 - val_mape: 344393.6562\n",
            "Epoch 423/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351047.0938 - val_loss: 0.0069 - val_mape: 361750.1250\n",
            "Epoch 424/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351889.4375 - val_loss: 0.0070 - val_mape: 343022.5625\n",
            "Epoch 425/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352073.0000 - val_loss: 0.0070 - val_mape: 348991.0625\n",
            "Epoch 426/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351682.0625 - val_loss: 0.0070 - val_mape: 394048.1250\n",
            "Epoch 427/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352262.5000 - val_loss: 0.0069 - val_mape: 363664.4062\n",
            "Epoch 428/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350976.0000 - val_loss: 0.0070 - val_mape: 354980.3438\n",
            "Epoch 429/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 353099.8125 - val_loss: 0.0069 - val_mape: 373270.0938\n",
            "Epoch 430/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350476.0312 - val_loss: 0.0070 - val_mape: 371593.8438\n",
            "Epoch 431/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352261.1562 - val_loss: 0.0070 - val_mape: 385175.4062\n",
            "Epoch 432/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 353464.1250 - val_loss: 0.0071 - val_mape: 409657.5625\n",
            "Epoch 433/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350405.5000 - val_loss: 0.0069 - val_mape: 355795.7188\n",
            "Epoch 434/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351232.5625 - val_loss: 0.0070 - val_mape: 339036.1875\n",
            "Epoch 435/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350912.4062 - val_loss: 0.0069 - val_mape: 376461.4688\n",
            "Epoch 436/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350488.0000 - val_loss: 0.0070 - val_mape: 344851.5938\n",
            "Epoch 437/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351804.5625 - val_loss: 0.0069 - val_mape: 376459.9062\n",
            "Epoch 438/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350532.1875 - val_loss: 0.0070 - val_mape: 377411.3125\n",
            "Epoch 439/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350102.7500 - val_loss: 0.0070 - val_mape: 360455.4375\n",
            "Epoch 440/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352703.9375 - val_loss: 0.0070 - val_mape: 329546.2500\n",
            "Epoch 441/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350845.2188 - val_loss: 0.0069 - val_mape: 359365.9688\n",
            "Epoch 442/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350892.5938 - val_loss: 0.0070 - val_mape: 367095.4375\n",
            "Epoch 443/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350623.6250 - val_loss: 0.0069 - val_mape: 363464.9375\n",
            "Epoch 444/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 350534.9688 - val_loss: 0.0069 - val_mape: 360112.1250\n",
            "Epoch 445/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350950.7188 - val_loss: 0.0069 - val_mape: 361250.3438\n",
            "Epoch 446/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351139.9375 - val_loss: 0.0069 - val_mape: 351457.2188\n",
            "Epoch 447/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351507.1562 - val_loss: 0.0070 - val_mape: 400103.9062\n",
            "Epoch 448/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351589.7500 - val_loss: 0.0070 - val_mape: 351118.9375\n",
            "Epoch 449/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 349940.7812 - val_loss: 0.0069 - val_mape: 360623.0625\n",
            "Epoch 450/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 349477.8125 - val_loss: 0.0070 - val_mape: 384560.1250\n",
            "Epoch 451/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 349763.8750 - val_loss: 0.0071 - val_mape: 388530.6875\n",
            "Epoch 452/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350120.2500 - val_loss: 0.0070 - val_mape: 331082.8125\n",
            "Epoch 453/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350753.9062 - val_loss: 0.0070 - val_mape: 381348.1875\n",
            "Epoch 454/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348531.6562 - val_loss: 0.0069 - val_mape: 365674.0625\n",
            "Epoch 455/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351676.5312 - val_loss: 0.0070 - val_mape: 377952.3750\n",
            "Epoch 456/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351139.5938 - val_loss: 0.0069 - val_mape: 374974.9688\n",
            "Epoch 457/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350982.9375 - val_loss: 0.0069 - val_mape: 364701.4062\n",
            "Epoch 458/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350370.0000 - val_loss: 0.0070 - val_mape: 394690.7188\n",
            "Epoch 459/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350426.4375 - val_loss: 0.0070 - val_mape: 395700.3438\n",
            "Epoch 460/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 352549.0625 - val_loss: 0.0069 - val_mape: 364241.3125\n",
            "Epoch 461/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 349484.1875 - val_loss: 0.0070 - val_mape: 349988.5312\n",
            "Epoch 462/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350964.5000 - val_loss: 0.0070 - val_mape: 334839.0000\n",
            "Epoch 463/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351248.9375 - val_loss: 0.0069 - val_mape: 354432.9062\n",
            "Epoch 464/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351381.8438 - val_loss: 0.0070 - val_mape: 338974.7500\n",
            "Epoch 465/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350438.8125 - val_loss: 0.0069 - val_mape: 348513.9062\n",
            "Epoch 466/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351679.9688 - val_loss: 0.0069 - val_mape: 368911.1250\n",
            "Epoch 467/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351520.7500 - val_loss: 0.0070 - val_mape: 376001.7812\n",
            "Epoch 468/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351808.5625 - val_loss: 0.0070 - val_mape: 381983.3125\n",
            "Epoch 469/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 352389.6875 - val_loss: 0.0071 - val_mape: 422613.9688\n",
            "Epoch 470/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348483.9062 - val_loss: 0.0070 - val_mape: 382169.8438\n",
            "Epoch 471/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 349067.7500 - val_loss: 0.0069 - val_mape: 395047.6250\n",
            "Epoch 472/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350190.6250 - val_loss: 0.0070 - val_mape: 362887.3125\n",
            "Epoch 473/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350902.4375 - val_loss: 0.0069 - val_mape: 369981.2812\n",
            "Epoch 474/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0073 - mape: 349749.8125 - val_loss: 0.0070 - val_mape: 324840.5000\n",
            "Epoch 475/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 351635.6250 - val_loss: 0.0069 - val_mape: 329021.4062\n",
            "Epoch 476/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350803.2812 - val_loss: 0.0070 - val_mape: 401291.6250\n",
            "Epoch 477/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348889.8438 - val_loss: 0.0069 - val_mape: 374282.1250\n",
            "Epoch 478/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350474.3438 - val_loss: 0.0069 - val_mape: 393931.6562\n",
            "Epoch 479/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350158.8438 - val_loss: 0.0069 - val_mape: 356943.1250\n",
            "Epoch 480/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348735.8125 - val_loss: 0.0071 - val_mape: 344233.1562\n",
            "Epoch 481/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350706.2812 - val_loss: 0.0070 - val_mape: 362072.8750\n",
            "Epoch 482/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350147.2500 - val_loss: 0.0069 - val_mape: 366366.8438\n",
            "Epoch 483/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350358.9688 - val_loss: 0.0070 - val_mape: 346093.0312\n",
            "Epoch 484/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350417.9062 - val_loss: 0.0070 - val_mape: 366180.1250\n",
            "Epoch 485/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 349950.6875 - val_loss: 0.0069 - val_mape: 365035.6250\n",
            "Epoch 486/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350447.3750 - val_loss: 0.0069 - val_mape: 357644.4375\n",
            "Epoch 487/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 347921.2812 - val_loss: 0.0069 - val_mape: 369503.0938\n",
            "Epoch 488/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 349506.5625 - val_loss: 0.0070 - val_mape: 373635.4688\n",
            "Epoch 489/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350849.1562 - val_loss: 0.0070 - val_mape: 408897.8125\n",
            "Epoch 490/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348838.0938 - val_loss: 0.0071 - val_mape: 421538.3750\n",
            "Epoch 491/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348457.8750 - val_loss: 0.0071 - val_mape: 407697.5312\n",
            "Epoch 492/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348382.3125 - val_loss: 0.0070 - val_mape: 374022.5625\n",
            "Epoch 493/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 351393.5938 - val_loss: 0.0069 - val_mape: 343110.5625\n",
            "Epoch 494/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 347444.1875 - val_loss: 0.0069 - val_mape: 355090.6562\n",
            "Epoch 495/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348105.4062 - val_loss: 0.0069 - val_mape: 355159.4375\n",
            "Epoch 496/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 347241.7500 - val_loss: 0.0070 - val_mape: 394279.0938\n",
            "Epoch 497/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348960.9062 - val_loss: 0.0069 - val_mape: 385605.0625\n",
            "Epoch 498/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 349989.1875 - val_loss: 0.0069 - val_mape: 334692.6875\n",
            "Epoch 499/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348779.5000 - val_loss: 0.0069 - val_mape: 331436.8438\n",
            "Epoch 500/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348035.9062 - val_loss: 0.0069 - val_mape: 358420.4375\n",
            "Epoch 501/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348521.1562 - val_loss: 0.0069 - val_mape: 395730.4062\n",
            "Epoch 502/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348922.9688 - val_loss: 0.0069 - val_mape: 368872.0625\n",
            "Epoch 503/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 347250.7500 - val_loss: 0.0069 - val_mape: 365124.5625\n",
            "Epoch 504/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348392.9375 - val_loss: 0.0070 - val_mape: 338014.4062\n",
            "Epoch 505/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 346980.1250 - val_loss: 0.0070 - val_mape: 327870.8750\n",
            "Epoch 506/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348327.6875 - val_loss: 0.0071 - val_mape: 391349.9062\n",
            "Epoch 507/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 349133.2188 - val_loss: 0.0070 - val_mape: 382735.0625\n",
            "Epoch 508/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348115.1562 - val_loss: 0.0070 - val_mape: 352930.6562\n",
            "Epoch 509/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 347839.7812 - val_loss: 0.0070 - val_mape: 376484.1562\n",
            "Epoch 510/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 347056.5938 - val_loss: 0.0070 - val_mape: 382832.5000\n",
            "Epoch 511/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 349414.9688 - val_loss: 0.0071 - val_mape: 385440.1250\n",
            "Epoch 512/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 350143.9688 - val_loss: 0.0069 - val_mape: 380213.4688\n",
            "Epoch 513/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348090.1250 - val_loss: 0.0070 - val_mape: 394781.5938\n",
            "Epoch 514/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350149.5000 - val_loss: 0.0071 - val_mape: 385225.7500\n",
            "Epoch 515/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348600.3438 - val_loss: 0.0069 - val_mape: 380592.4062\n",
            "Epoch 516/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 350474.5312 - val_loss: 0.0070 - val_mape: 351062.8125\n",
            "Epoch 517/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348826.6875 - val_loss: 0.0069 - val_mape: 378934.2500\n",
            "Epoch 518/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348457.7812 - val_loss: 0.0072 - val_mape: 345267.9688\n",
            "Epoch 519/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 349197.7500 - val_loss: 0.0071 - val_mape: 406094.1250\n",
            "Epoch 520/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 348162.3750 - val_loss: 0.0072 - val_mape: 397061.4375\n",
            "Epoch 521/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 347263.6250 - val_loss: 0.0070 - val_mape: 332004.3125\n",
            "Epoch 522/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 346214.4375 - val_loss: 0.0071 - val_mape: 314818.4062\n",
            "Epoch 523/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 347400.4062 - val_loss: 0.0071 - val_mape: 336030.3438\n",
            "Epoch 524/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 346101.8438 - val_loss: 0.0070 - val_mape: 346443.0000\n",
            "Epoch 525/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 346482.3125 - val_loss: 0.0069 - val_mape: 374289.0312\n",
            "Epoch 526/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 347541.1562 - val_loss: 0.0071 - val_mape: 390564.6875\n",
            "Epoch 527/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 346244.0312 - val_loss: 0.0069 - val_mape: 343828.0938\n",
            "Epoch 528/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 346421.1875 - val_loss: 0.0072 - val_mape: 342816.4375\n",
            "Epoch 529/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 347830.2812 - val_loss: 0.0069 - val_mape: 359903.8438\n",
            "Epoch 530/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 346375.5625 - val_loss: 0.0071 - val_mape: 402480.6562\n",
            "Epoch 531/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 347418.4062 - val_loss: 0.0069 - val_mape: 379735.2812\n",
            "Epoch 532/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 345768.5312 - val_loss: 0.0070 - val_mape: 387057.7500\n",
            "Epoch 533/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 345749.9062 - val_loss: 0.0071 - val_mape: 410894.5312\n",
            "Epoch 534/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 347255.6250 - val_loss: 0.0071 - val_mape: 346088.3438\n",
            "Epoch 535/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348385.0000 - val_loss: 0.0071 - val_mape: 322938.4062\n",
            "Epoch 536/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 348196.7500 - val_loss: 0.0069 - val_mape: 361010.2188\n",
            "Epoch 537/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 347279.2500 - val_loss: 0.0069 - val_mape: 371306.2812\n",
            "Epoch 538/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 345291.0312 - val_loss: 0.0069 - val_mape: 375780.0000\n",
            "Epoch 539/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 345307.4688 - val_loss: 0.0069 - val_mape: 377654.0625\n",
            "Epoch 540/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 344981.8750 - val_loss: 0.0069 - val_mape: 356395.5938\n",
            "Epoch 541/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 346506.5312 - val_loss: 0.0071 - val_mape: 374870.5000\n",
            "Epoch 542/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 346850.1562 - val_loss: 0.0070 - val_mape: 327148.6562\n",
            "Epoch 543/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 346576.2500 - val_loss: 0.0069 - val_mape: 379064.2188\n",
            "Epoch 544/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 345076.9062 - val_loss: 0.0070 - val_mape: 370049.9375\n",
            "Epoch 545/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 346313.8750 - val_loss: 0.0069 - val_mape: 366873.5938\n",
            "Epoch 546/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 344705.8750 - val_loss: 0.0070 - val_mape: 370563.5000\n",
            "Epoch 547/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 343616.5312 - val_loss: 0.0072 - val_mape: 425087.1562\n",
            "Epoch 548/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 346207.0312 - val_loss: 0.0070 - val_mape: 330204.2188\n",
            "Epoch 549/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 344915.7500 - val_loss: 0.0069 - val_mape: 382673.5938\n",
            "Epoch 550/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0073 - mape: 345912.0000 - val_loss: 0.0070 - val_mape: 336367.4062\n",
            "Epoch 551/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 345763.2812 - val_loss: 0.0072 - val_mape: 354183.4375\n",
            "Epoch 552/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 346403.5312 - val_loss: 0.0069 - val_mape: 337017.0000\n",
            "Epoch 553/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 345765.8125 - val_loss: 0.0070 - val_mape: 346876.8750\n",
            "Epoch 554/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 343961.2812 - val_loss: 0.0069 - val_mape: 340294.7188\n",
            "Epoch 555/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0073 - mape: 345386.5938 - val_loss: 0.0071 - val_mape: 421369.5312\n",
            "Epoch 556/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 342858.3125 - val_loss: 0.0069 - val_mape: 366359.9062\n",
            "Epoch 557/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 344932.1562 - val_loss: 0.0069 - val_mape: 335863.7500\n",
            "Epoch 558/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 345256.1250 - val_loss: 0.0072 - val_mape: 327947.7812\n",
            "Epoch 559/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 344338.0938 - val_loss: 0.0069 - val_mape: 349171.0625\n",
            "Epoch 560/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 345860.7500 - val_loss: 0.0071 - val_mape: 394452.0000\n",
            "Epoch 561/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 346088.1250 - val_loss: 0.0073 - val_mape: 333860.3438\n",
            "Epoch 562/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 343748.3750 - val_loss: 0.0070 - val_mape: 377158.2812\n",
            "Epoch 563/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 343308.3125 - val_loss: 0.0069 - val_mape: 359483.0938\n",
            "Epoch 564/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 342699.2188 - val_loss: 0.0070 - val_mape: 356038.0625\n",
            "Epoch 565/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 344150.5938 - val_loss: 0.0075 - val_mape: 308908.0312\n",
            "Epoch 566/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 342846.8438 - val_loss: 0.0070 - val_mape: 341968.7812\n",
            "Epoch 567/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 344350.5312 - val_loss: 0.0069 - val_mape: 342760.4375\n",
            "Epoch 568/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 343524.2812 - val_loss: 0.0071 - val_mape: 410849.0000\n",
            "Epoch 569/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 344902.7500 - val_loss: 0.0069 - val_mape: 380646.2188\n",
            "Epoch 570/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 344777.5312 - val_loss: 0.0072 - val_mape: 319990.0938\n",
            "Epoch 571/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 342559.1562 - val_loss: 0.0073 - val_mape: 329755.6250\n",
            "Epoch 572/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 342528.5625 - val_loss: 0.0069 - val_mape: 368455.1875\n",
            "Epoch 573/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 345610.4062 - val_loss: 0.0071 - val_mape: 346829.6250\n",
            "Epoch 574/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 344171.1250 - val_loss: 0.0069 - val_mape: 365283.6875\n",
            "Epoch 575/600\n",
            "1121/1121 [==============================] - 13s 11ms/step - loss: 0.0072 - mape: 343614.5938 - val_loss: 0.0070 - val_mape: 353912.0312\n",
            "Epoch 576/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 343594.4062 - val_loss: 0.0069 - val_mape: 364168.0000\n",
            "Epoch 577/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 342444.4062 - val_loss: 0.0070 - val_mape: 373746.4062\n",
            "Epoch 578/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 343924.5625 - val_loss: 0.0069 - val_mape: 332748.6562\n",
            "Epoch 579/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 342989.3438 - val_loss: 0.0069 - val_mape: 347464.1875\n",
            "Epoch 580/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 343997.7500 - val_loss: 0.0070 - val_mape: 394460.1875\n",
            "Epoch 581/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 341746.0938 - val_loss: 0.0072 - val_mape: 329611.3438\n",
            "Epoch 582/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 341067.7812 - val_loss: 0.0069 - val_mape: 399778.5312\n",
            "Epoch 583/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 342665.8125 - val_loss: 0.0071 - val_mape: 355275.5625\n",
            "Epoch 584/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 343132.3438 - val_loss: 0.0071 - val_mape: 299655.0000\n",
            "Epoch 585/600\n",
            "1121/1121 [==============================] - 11s 10ms/step - loss: 0.0072 - mape: 344077.5312 - val_loss: 0.0070 - val_mape: 387012.6562\n",
            "Epoch 586/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 343066.0000 - val_loss: 0.0068 - val_mape: 369788.0938\n",
            "Epoch 587/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 342832.8438 - val_loss: 0.0078 - val_mape: 442665.8750\n",
            "Epoch 588/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 342365.6562 - val_loss: 0.0069 - val_mape: 345193.6562\n",
            "Epoch 589/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 342071.0625 - val_loss: 0.0069 - val_mape: 338935.8125\n",
            "Epoch 590/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 342274.8125 - val_loss: 0.0070 - val_mape: 416526.5000\n",
            "Epoch 591/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 344014.3438 - val_loss: 0.0071 - val_mape: 382328.6875\n",
            "Epoch 592/600\n",
            "1121/1121 [==============================] - 12s 11ms/step - loss: 0.0072 - mape: 343283.5000 - val_loss: 0.0074 - val_mape: 306310.5938\n",
            "Epoch 593/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 344145.8750 - val_loss: 0.0069 - val_mape: 360697.1250\n",
            "Epoch 594/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 344061.5625 - val_loss: 0.0072 - val_mape: 322763.5625\n",
            "Epoch 595/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 343032.5312 - val_loss: 0.0070 - val_mape: 312082.0625\n",
            "Epoch 596/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 341732.3125 - val_loss: 0.0074 - val_mape: 417577.5625\n",
            "Epoch 597/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 343545.1875 - val_loss: 0.0071 - val_mape: 405311.1875\n",
            "Epoch 598/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 343130.0938 - val_loss: 0.0074 - val_mape: 269028.2500\n",
            "Epoch 599/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 341022.3125 - val_loss: 0.0071 - val_mape: 359926.0625\n",
            "Epoch 600/600\n",
            "1121/1121 [==============================] - 12s 10ms/step - loss: 0.0072 - mape: 345524.5625 - val_loss: 0.0073 - val_mape: 330374.4062\n"
          ]
        }
      ],
      "source": [
        "!python train.py --model gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "3jNAdgvF8glM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a534f2ae-7192-4b9b-e7af-87f55a8ff6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-22 01:44:07.285062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-22 01:44:08.134675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-22 01:44:10.472889: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:44:10.474036: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:44:10.475030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:44:10.735453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:44:10.739802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:44:10.741423: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "Epoch 1/5\n",
            "2023-08-22 01:44:11.332705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:44:11.334222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:44:11.335741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:44:11.570328: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:44:11.571876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:44:11.573244: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:44:12.524522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:44:12.525763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:44:12.526859: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:44:12.720866: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:44:12.722130: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:44:12.723272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "1117/1121 [============================>.] - ETA: 0s - loss: 0.0172 - mape: 1404807.12502023-08-22 01:44:27.611921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:44:27.613053: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:44:27.614098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:44:27.797459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:44:27.798589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:44:27.799628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "1121/1121 [==============================] - 17s 13ms/step - loss: 0.0172 - mape: 1405067.0000 - val_loss: 0.0153 - val_mape: 983943.5000\n",
            "Epoch 2/5\n",
            "1121/1121 [==============================] - 14s 12ms/step - loss: 0.0147 - mape: 1224430.0000 - val_loss: 0.0152 - val_mape: 988550.1875\n",
            "Epoch 3/5\n",
            "1121/1121 [==============================] - 13s 12ms/step - loss: 0.0145 - mape: 1207794.8750 - val_loss: 0.0147 - val_mape: 1134480.3750\n",
            "Epoch 4/5\n",
            "1121/1121 [==============================] - 14s 12ms/step - loss: 0.0135 - mape: 1131900.8750 - val_loss: 0.0145 - val_mape: 1172039.0000\n",
            "Epoch 5/5\n",
            "1121/1121 [==============================] - 14s 12ms/step - loss: 0.0095 - mape: 655231.0625 - val_loss: 0.0117 - val_mape: 337379.2188\n"
          ]
        }
      ],
      "source": [
        "!python train.py --model lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "FW18-qF88glN"
      },
      "outputs": [],
      "source": [
        "!python train.py --model saes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "Qlf7TLFq8glO",
        "outputId": "ece57ac0-1373-4866-b920-7d3490f1c4f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-22 01:43:03.447513: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-22 01:43:05.003607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-22 01:43:07.266335: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:43:07.267600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:43:07.268723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:43:07.469198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:43:07.470418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:43:07.471534: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:43:07.709683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:43:07.710810: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:43:07.711870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:43:07.890544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:43:07.891816: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:43:07.892894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:43:09.760111: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:43:09.761242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:43:09.762268: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-08-22 01:43:09.920175: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-08-22 01:43:09.921319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-08-22 01:43:09.922519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "3144/3144 [==============================] - 5s 1ms/step\n",
            "LSTM\n",
            "explained_variance_score:0.432872\n",
            "mape:172.971446%\n",
            "mae:45.312382\n",
            "mse:4268.902272\n",
            "rmse:65.336837\n",
            "r2:0.430698\n",
            "Figure(640x480)\n"
          ]
        }
      ],
      "source": [
        "!python main.py"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}